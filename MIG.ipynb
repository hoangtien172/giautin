{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKtw6qw7J8bS"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, LSTM, Dense, TimeDistributed, Reshape, MaxPooling2D\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2DTranspose, Bidirectional, Flatten,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import BatchNormalization, RepeatVector\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "# from keras.layers import dot\n",
        "# from keras.layers import concatenate\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(256, return_sequences=True), input_shape=(1,76)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Bidirectional(LSTM(128), name=\"feature\"))\n",
        "    model.add(Dense(2))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAWnfNzGEx-V"
      },
      "source": [
        "X_train = np.load(\"data/X_train.npy\")\n",
        "X_test = np.load(\"data/X_test.npy\")\n",
        "y_train = np.load(\"data/y_train.npy\")\n",
        "y_test = np.load(\"data/y_test.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvrMS3LEX-QB"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7lRASM4Ex-V"
      },
      "source": [
        "y_train = np.argmax(y_train, axis=1)\n",
        "y_test = np.argmax(y_test, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrvdq-VJEx-W"
      },
      "source": [
        "np.squeeze(X_train).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK7p0M9JEx-W"
      },
      "source": [
        "import json\n",
        "\n",
        "with open (\"X_train.json\", 'r') as f:\n",
        "    mapping_X_train = json.load(f)\n",
        "# with open (\"X_test.json\", 'r') as f:\n",
        "#     mapping_X_test = json.load(f)\n",
        "# mapping_Y_train = np.load(\"mapping/IP_label_train.npy\")\n",
        "# mapping_Y_test = np.load(\"mapping/IP_test_test.npy\")\n",
        "\n",
        "# mapping_Y_train = np.argmax(mapping_Y_train, axis=1)\n",
        "# mapping_Y_test = np.argmax(mapping_Y_test, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_83O9T9Daf0e"
      },
      "source": [
        "stats = {}\n",
        "for ip, flow in tqdm(mapping_X_train.items()):\n",
        "    num_flow = len(flow)\n",
        "    if num_flow not in stats.keys():\n",
        "        stats[num_flow] = 1\n",
        "    else:\n",
        "        stats[num_flow] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DHoKC2cbOr2"
      },
      "source": [
        "num_flows = list(stats.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cELCUGfJbXPm"
      },
      "source": [
        "num_flows.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e4_DQNfbXRy"
      },
      "source": [
        "min(num_flows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Seq-gw1NbXT2"
      },
      "source": [
        "stats[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vxXSc26bXVi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HogPd9sEx-W"
      },
      "source": [
        "lstm_model = load_model(\"checkpoint.hdf5\")\n",
        "# lstm_model.load_weights('checkpoint.hdf5')\n",
        "# loss, acc = model.evaluate(X_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0s0YfDuEx-X"
      },
      "source": [
        "feat_extractor = Model(inputs=lstm_model.input, outputs=lstm_model.get_layer(\"flatten_3\").output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp0TBNhxEx-X"
      },
      "source": [
        "def combine(x, y, mapping):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for pair, item in tqdm(mapping.items()):\n",
        "        X.append(np.mean(x[item], axis=0))\n",
        "        Y.append(np.mean(y[item], axis=0))\n",
        "    X = np.stack(X, axis=0)\n",
        "    Y = np.stack(Y, axis=0)\n",
        "    \n",
        "    return np.squeeze(X), Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9KZgXtwWGlI"
      },
      "source": [
        "# feature_train = feat_extractor.predict(X_train)\n",
        "# feature_test = feat_extractor.predict(X_test)\n",
        "\n",
        "feature_train = X_train\n",
        "feature_test = X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-f3jCK8Ex-X"
      },
      "source": [
        "X_train_ip, Y_train_ip = combine(feature_train, y_train, mapping_X_train)\n",
        "X_test_ip, Y_test_ip = combine(feature_test, y_test, mapping_X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECMDMEhtEx-X"
      },
      "source": [
        "list_X_train_ip = list(mapping_X_train.keys())\n",
        "list_X_test_ip = list(mapping_X_test.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7YrDdRAWGlJ"
      },
      "source": [
        "for i in list_X_test_ip:\n",
        "    if i in list_X_train_ip:\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUyDj-yMEx-Y"
      },
      "source": [
        "def get_edges(list_ip, Y_ip):\n",
        "    edge_index = []\n",
        "    for i in tqdm(range(0, len(list_ip))):\n",
        "        ip1, ip2 = list_ip[i].split(\"-\")\n",
        "        for j in range(0, len(list_ip)):\n",
        "            if (ip1 in list_ip[j]) or (ip2 in list_ip[j]):\n",
        "                if Y_ip[i] != Y_ip[j]:\n",
        "                    edge_index.append([i, j])\n",
        "    edge_indices = np.array(edge_index)\n",
        "    \n",
        "    return edge_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDNnzxTnEx-Y"
      },
      "source": [
        "edge_indices_train = get_edges(list_X_train_ip, Y_train_ip)\n",
        "edge_indices_test = get_edges(list_X_test_ip, Y_test_ip)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wn6RvAzEx-Y"
      },
      "source": [
        "edge_indices_train = np.load(\"edge_index.npy\")\n",
        "edge_indices_test = np.load(\"edge_index_test.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBDXV6BjEx-Y"
      },
      "source": [
        "from kgcnn.data.cora.cora_lu import cora_graph\n",
        "from kgcnn.literature.GCN import make_gcn\n",
        "from kgcnn.literature.GNNExplain import GNNExplainer, GNNInterface\n",
        "from kgcnn.utils.adj import precompute_adjacency_scaled, sort_edge_indices, make_adjacency_from_edge_indices, make_adjacency_undirected_logical_or, convert_scaled_adjacency_to_list\n",
        "from kgcnn.utils.data import ragged_tensor_from_nested_numpy\n",
        "from kgcnn.utils.learning import lr_lin_reduction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "922ndfEMEx-Z"
      },
      "source": [
        "edge_index_sorted_train = sort_edge_indices(edge_indices_train)\n",
        "adj_matrix_train = make_adjacency_from_edge_indices(edge_index_sorted_train)\n",
        "adj_matrix_train = precompute_adjacency_scaled(make_adjacency_undirected_logical_or(adj_matrix_train))\n",
        "edge_index_train, edge_weight_train = convert_scaled_adjacency_to_list(adj_matrix_train)\n",
        "edge_weight_train = np.expand_dims(edge_weight_train, axis=-1)\n",
        "\n",
        "edge_index_sorted_test = sort_edge_indices(edge_indices_test)\n",
        "adj_matrix_test = make_adjacency_from_edge_indices(edge_index_sorted_test)\n",
        "adj_matrix_test = precompute_adjacency_scaled(make_adjacency_undirected_logical_or(adj_matrix_test))\n",
        "edge_index_test, edge_weight_test = convert_scaled_adjacency_to_list(adj_matrix_test)\n",
        "edge_weight_test = np.expand_dims(edge_weight_test, axis=-1)\n",
        "\n",
        "y_train_ip = np.expand_dims(Y_train_ip, axis=-1)\n",
        "y_train_ip = np.array(y_train_ip == np.arange(2), dtype=np.float32)\n",
        "\n",
        "y_test_ip = np.expand_dims(Y_test_ip, axis=-1)\n",
        "y_test_ip = np.array(y_test_ip == np.arange(2), dtype=np.float32)\n",
        "\n",
        "nodes_train, edges_train, edge_indices_train = ragged_tensor_from_nested_numpy([X_train_ip]), ragged_tensor_from_nested_numpy(\n",
        "    [edge_weight_train]), ragged_tensor_from_nested_numpy([edge_index_train])\n",
        "\n",
        "nodes_test, edges_test, edge_indices_test = ragged_tensor_from_nested_numpy([X_test_ip]), ragged_tensor_from_nested_numpy(\n",
        "    [edge_weight_test]), ragged_tensor_from_nested_numpy([edge_index_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvuTITmFEx-Z"
      },
      "source": [
        "xtrain = nodes_train, edges_train, edge_indices_train\n",
        "ytrain = np.expand_dims(y_train_ip, axis=0)\n",
        "\n",
        "xtest = nodes_test, edges_test, edge_indices_test\n",
        "ytest = np.expand_dims(y_test_ip, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awTu_NBEEx-a"
      },
      "source": [
        "# inds = np.arange(len(labels))\n",
        "# ind_train, ind_val = train_test_split(inds, test_size=0.10, random_state=0)\n",
        "# val_mask = np.zeros_like(inds)\n",
        "# train_mask = np.zeros_like(inds)\n",
        "# val_mask[ind_val] = 1\n",
        "# train_mask[ind_train] = 1\n",
        "# val_mask = np.expand_dims(val_mask, axis=0)  # One graph in batch\n",
        "# train_mask = np.expand_dims(train_mask, axis=0)  # One graph in batch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC83AtIQEx-a"
      },
      "source": [
        "model = make_gcn(\n",
        "    input_node_shape=[None, 1032],\n",
        "    input_edge_shape=[None, 1],\n",
        "    # Output\n",
        "    output_embedd={\"output_mode\": 'node'},\n",
        "    output_mlp={\"use_bias\": [True, False], \"units\": [ 16, 2], \"activation\": [ 'gelu', 'softmax']},\n",
        "    # model specs\n",
        "    depth=2,\n",
        "    gcn_args={\"units\": 2, \"use_bias\": True, \"activation\": \"gelu\", \"has_unconnected\": False}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT3AcGmdEx-a"
      },
      "source": [
        "learning_rate_start = 1e-3\n",
        "learning_rate_stop = 1e-4\n",
        "epo = 40\n",
        "epomin = 260\n",
        "epostep = 10\n",
        "\n",
        "# Compile model with optimizer and loss\n",
        "optimizer = tf.keras.optimizers.Adam(lr=learning_rate_start)\n",
        "# cbks = tf.keras.callbacks.LearningRateScheduler(lr_lin_reduction(learning_rate_start, learning_rate_stop, epomin, epo))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              weighted_metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# Training loop\n",
        "trainlossall = []\n",
        "testlossall = []\n",
        "# start = time.process_time()\n",
        "hist = model.fit(xtrain, ytrain,\n",
        "                 epochs=epo,\n",
        "                 batch_size=32,\n",
        "#                  callbacks=[cbks],\n",
        "                 validation_freq=epostep,\n",
        "                 validation_data=(xtest, ytest),\n",
        "                 verbose=2\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}